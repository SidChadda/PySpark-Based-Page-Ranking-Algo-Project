{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7CqdE1VhI8_"
   },
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
    "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
    "\n",
    "import findspark\n",
    "findspark.init(\"spark-2.4.4-bin-hadoop2.7\")# SPARK_HOME\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22126,
     "status": "ok",
     "timestamp": 1582141382604,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "4wvdXQxh9m2f",
    "outputId": "8c519e03-06fb-4f4d-c5c4-78d926f7effd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25367,
     "status": "ok",
     "timestamp": 1582141385874,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "tFQa1qU-Ml-B",
    "outputId": "1ed31ae1-6dc6-4231-dd5d-cded58f36acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Put input_docs_sample.zip in your Google Drive\n",
    "\n",
    "!rm -rf input_docs\n",
    "!cp /content/drive/My\\ Drive/input_docs_sample.zip .\n",
    "!unzip input_docs_sample.zip > /dev/null\n",
    "!ls input_docs/ | wc -l\n",
    "\n",
    "# for the real collection change above input_docs_sample.zip to input_docs.zip\n",
    "# for the sample collection of 5 docs, the process is fast\n",
    "# for the real collection, the process takes about 6 min (start to finish, the whole notebook) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26044,
     "status": "ok",
     "timestamp": 1582141386578,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "SW0lXYo6Hqso",
    "outputId": "71d4f36c-b5ed-4c8b-daa1-9d8b1dfd055a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "usmMrr5Uhipf"
   },
   "source": [
    "**Create an RDD from a text file**\n",
    "\n",
    "Each line of the text file becomes an element of the RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28153,
     "status": "ok",
     "timestamp": 1582141388723,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "TVfPs26GjAal",
    "outputId": "e691ff51-d850-479c-e251-c736bd833903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, '<H2>26-FEB-1987 15:01:01.79</H2>\\r\\n<H2>BAHIA COCOA REVIEW</H2>\\r\\nShowers continued throughout the week in\\nthe Bahia cocoa zone, alleviating the drought since early\\nJanuary and improving prospects for the coming temporao,\\nalthough normal humidity levels have not been restored,\\nComissaria Smith said in its weekly review.\\n    The dry period means the temporao will be late this year.\\n    Arrivals for the week ended February 22 were 155,221 bags\\nof 60 kilos making a cumulative total for the season of 5.93\\nmln against 5.81 at the same stage last year. Again it seems\\nthat cocoa delivered earlier on consignment was included in the\\narrivals figures.\\n    Comissaria Smith said there is still some doubt as to how\\nmuch old crop cocoa is still available as harvesting has\\npractically come to an end. With total Bahia crop estimates\\naround 6.4 mln bags and sales standing at almost 6.2 mln there\\nare a few hundred thousand bags still in the hands of farmers,\\nmiddlemen, exporters and processors.\\n    There are doubts as to how much of this cocoa would be fit\\nfor export as shippers are now experiencing dificulties in\\nobtaining +Bahia superior+ certificates.\\n    In view of the lower quality over recent weeks farmers have\\nsold a good part of their cocoa held on consignment.\\n    Comissaria Smith said spot bean prices rose to 340 to 350\\ncruzados per arroba of 15 kilos.\\n    Bean shippers were reluctant to offer nearby shipment and\\nonly limited sales were booked for March shipment at 1,750 to\\n1,780 dlrs per tonne to ports to be named.\\n    New crop sales were also light and all to open ports with\\nJune/July going at 1,850 and 1,880 dlrs and at 35 and 45 dlrs\\nunder New York july, Aug/Sept at 1,870, 1,875 and 1,880 dlrs\\nper tonne FOB.\\n    Routine sales of butter were made. March/April sold at\\n4,340, 4,345 and 4,350 dlrs.\\n    April/May butter went at 2.27 times New York May, June/July\\nat 4,400 and 4,415 dlrs, Aug/Sept at 4,351 to 4,450 dlrs and at\\n2.27 and 2.28 times New York Sept and Oct/Dec at 4,480 dlrs and\\n2.27 times New York Dec, Comissaria Smith said.\\n    Destinations were the U.S., Covertible currency areas,\\nUruguay and open ports.\\n    Cake sales were registered at 785 to 995 dlrs for\\nMarch/April, 785 dlrs for May, 753 dlrs for Aug and 0.39 times\\nNew York Dec for Oct/Dec.\\n    Buyers were the U.S., Argentina, Uruguay and convertible\\ncurrency areas.\\n    Liquor sales were limited with March/April selling at 2,325\\nand 2,380 dlrs, June/July at 2,375 dlrs and at 1.25 times New\\nYork July, Aug/Sept at 2,400 dlrs and at 1.25 times New York\\nSept and Oct/Dec at 1.25 times New York Dec, Comissaria Smith\\nsaid.\\n    Total Bahia sales are currently estimated at 6.13 mln bags\\nagainst the 1986/87 crop and 1.06 mln bags against the 1987/88\\ncrop.\\n    Final figures for the period to February 28 are expected to\\nbe published by the Brazilian Cocoa Trade Commission after\\ncarnival which ends midday on February 27.\\n \\n')]\n"
     ]
    }
   ],
   "source": [
    "# wholeTextFiles generates an RDD of pair values, \n",
    "# where the key is the full path of each file, the value is the content of each file\n",
    "#input = sc.wholeTextFiles(\"/content/drive/My\\ Drive/input_docs\");\n",
    "input = sc.wholeTextFiles(\"input_docs\");\n",
    "\n",
    "# Now we strip the prefix of filenames and leave only the basename. \n",
    "# e.g. 'file:/content/drive/My Drive/Colab Notebooks/data_spark/input_docs/3.html'\n",
    "# becomes '3.html' \n",
    "import os\n",
    "\n",
    "#(did,text)\n",
    "input2 = input.map(lambda x: (int(os.path.basename(x[0]).split(\".\")[0]), x[1]))\n",
    "\n",
    "print(input2.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28546,
     "status": "ok",
     "timestamp": 1582141389136,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "AdFPY9uqgq1P",
    "outputId": "db1cb4dd-0fcf-4298-fe4a-a61bd076954a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(True, (True, True, True)), (True, (True, True, True))]\n"
     ]
    }
   ],
   "source": [
    "# Doc to wordlist function\n",
    "# The output will be a list of tuples such as \n",
    "# (\"apple\", (3,10,10/20)), \n",
    "# where 3 is docid, \n",
    "# 10 is frequency of \"apple\" in this doc, \n",
    "# 20 is maxf in in this doc.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# for a given doc return a list of tuples of the form (w, (docid, freq, freq/maxfreq))\n",
    "def dw(docid, htmltext):\n",
    "  cleantext = BeautifulSoup(htmltext).get_text()\n",
    "  #TODO\n",
    "  #returning just a dummy result\n",
    "  return [(_,(_,_,_))]\n",
    "\n",
    "word_docid_freq_tf = input2.flatMap(lambda x: dw(x[0],x[1]))\n",
    "\n",
    "print(word_docid_freq_tf.take(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SW_XxF-VveLF"
   },
   "source": [
    "Expected output (all expected results are on the small sample):\n",
    "\n",
    "<pre>\n",
    "[('feb', (1, 1, 0.07142857142857142)), ('bahia', (1, 5, 0.35714285714285715))]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZiKzsibkj92"
   },
   "outputs": [],
   "source": [
    "# Now create an RDD as follows \n",
    "# (word, [(did1,freq1,tf1), (did2,freq2,tf2), ...])\n",
    "\t\t    \n",
    "#TODO\n",
    "\n",
    "# creating a dummy RDD\n",
    "word_postinglist_freq_tf = sc.parallelize([ ('test', [(1, 1, 0.5), (2, 1, 0.2)]) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28629,
     "status": "ok",
     "timestamp": 1582141389268,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "gtDZ4q-1oaq1",
    "outputId": "640959df-0553-4090-ee57-578189d3c990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('test', [(1, 1, 0.5), (2, 1, 0.2)])]\n"
     ]
    }
   ],
   "source": [
    "print(word_postinglist_freq_tf.map(lambda x : (x[0], list(x[1]))).take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3UhcJ4_j1IPu"
   },
   "source": [
    "Expected output\n",
    "\n",
    "<pre>\n",
    "[('feb', [(1, 1, 0.07142857142857142), (2, 1, 0.2), (5, 1, 0.16666666666666666), (3, 1, 0.3333333333333333), (4, 1, 0.07142857142857142)]), ('bahia', [(1, 5, 0.35714285714285715)])]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28920,
     "status": "ok",
     "timestamp": 1582141389611,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "y_8KGpQvlLGp",
    "outputId": "c7831cf1-9d27-490c-97aa-bfa8460d6a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('test', [(1, 3, 0.12), (2, 5, 0.876)])]\n"
     ]
    }
   ],
   "source": [
    "# (word, [(did,freq,tfidf), ...])\n",
    "# We easily obtain idf as 1/len(postinglist_tf)\n",
    "# idf = 1/len(postinglist_tf)\n",
    "\n",
    "#TODO\n",
    "\n",
    "# creating a dummy RDD\n",
    "word_postinglist_freq_tfidf = sc.parallelize([('test', [(1,3,0.12), (2,5,0.876)])])\n",
    "\n",
    "print(word_postinglist_freq_tfidf.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pwXDgFxP2MMc"
   },
   "source": [
    "Expected output\n",
    "\n",
    "<pre>\n",
    "[('feb', [(1, 1, 0.014285714285714285), (2, 1, 0.04), (5, 1, 0.03333333333333333), (3, 1, 0.06666666666666667), (4, 1, 0.014285714285714285)])]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29114,
     "status": "ok",
     "timestamp": 1582141389864,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "U8jahG9q2SVf",
    "outputId": "255e8313-c44c-43dc-d36a-3dacd3b734e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, (3, 0.12)), (1, (5, 0.13))]\n",
      "[[(1, (5, 0.23)), (2, (6, 0.34))]]\n"
     ]
    }
   ],
   "source": [
    "# Now, we would like to obtain the magnitude of each doc.\n",
    "# First, produce (did, (freq,tfidf)) for each word of doc did; \n",
    "# We do don't need the word itself, just its (freq,tfidf). \n",
    "# Then, do reduceByKey on these tuples and obtain maxfreq and \n",
    "# magnitude (squared) for each document. \n",
    "\n",
    "#TODO\n",
    "\n",
    "# RDD of (did,(freq,tfidf)) tuples\n",
    "# creating a dummy RDD\n",
    "did_freq_tfidfsq_rdd = sc.parallelize([(1,(3,0.12)), (1,(5,0.13)), (2,(2,0.11)), (2,(6,0.14))])\n",
    "\n",
    "print(did_freq_tfidfsq_rdd.take(2))\n",
    "\n",
    "# Produce (did,(maxf,magnitudesq))\n",
    "# creating a dummy RDD\n",
    "doc_maxf_mag = sc.parallelize([[(1, (5, 0.23)), (2, (6, 0.34))]])\n",
    "\n",
    "print(doc_maxf_mag.take(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cnGnORtV8VhX"
   },
   "source": [
    "Excpected result\n",
    "\n",
    "<pre>\n",
    "[(1, (1, 0.0002040816326530612)), (2, (1, 0.0016))]\n",
    "[(2, (5, 3.894100000000001)), (4, (14, 2.94553429705215))]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zBByinGhlu7-"
   },
   "outputs": [],
   "source": [
    "!rm -rf inv_idx\n",
    "word_postinglist_freq_tfidf.saveAsTextFile(\"inv_idx\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szlsKC-RmWvd"
   },
   "outputs": [],
   "source": [
    "!rm -rf doc_mag\n",
    "doc_maxf_mag.saveAsTextFile(\"doc_mag\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36773,
     "status": "ok",
     "timestamp": 1582141397639,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "vNplByM4fsvF",
    "outputId": "ca89640b-1f82-4deb-f067-2bee45f22c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "-rw-r--r-- 1 root root  0 Feb 19 19:43 part-00000\n",
      "-rw-r--r-- 1 root root 40 Feb 19 19:43 part-00001\n",
      "-rw-r--r-- 1 root root  0 Feb 19 19:43 _SUCCESS\n",
      "('test', [(1, 3, 0.12), (2, 5, 0.876)])\n",
      "0 inv_idx/part-00000\n",
      "1 inv_idx/part-00001\n",
      "1 /content/drive/My Drive/inv_idx.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lrt inv_idx\n",
    "!head inv_idx/part-00001\n",
    "!wc -l inv_idx/part-00000\n",
    "!wc -l inv_idx/part-00001\n",
    "!cat inv_idx/part-00000 inv_idx/part-00001 > /content/drive/My\\ Drive/inv_idx.txt\n",
    "!wc -l /content/drive/My\\ Drive/inv_idx.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41345,
     "status": "ok",
     "timestamp": 1582141402240,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "Islv0-ONjyF1",
    "outputId": "dfd616d3-6698-4036-85eb-3f145717160c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "-rw-r--r-- 1 root root  0 Feb 19 19:43 part-00000\n",
      "-rw-r--r-- 1 root root 33 Feb 19 19:43 part-00001\n",
      "-rw-r--r-- 1 root root  0 Feb 19 19:43 _SUCCESS\n",
      "0 doc_mag/part-00000\n",
      "1 doc_mag/part-00001\n",
      "1 /content/drive/My Drive/doc_mag.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lrt doc_mag\n",
    "!head doc_mag/part-00000\n",
    "!wc -l doc_mag/part-00000\n",
    "!wc -l doc_mag/part-00001\n",
    "!cat doc_mag/part-00000 doc_mag/part-00001 > /content/drive/My\\ Drive/doc_mag.txt\n",
    "!wc -l /content/drive/My\\ Drive/doc_mag.txt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNWsvl1Nt1h3ORMUzuhvAlX",
   "name": "inverted-index-pyspark-post.ipynb",
   "provenance": [
    {
     "file_id": "1v32oL3K9ThAkiAzmmFHmPGOXCGJRpf-V",
     "timestamp": 1582136875828
    },
    {
     "file_id": "1sewOLGSDAtfhQvJRp11uC8E16fDAN-2J",
     "timestamp": 1581528484318
    },
    {
     "file_id": "1GJlpktDYsLj5m2sfewpoliYvuzmsHMlV",
     "timestamp": 1581284901759
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
