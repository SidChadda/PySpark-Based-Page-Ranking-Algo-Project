{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading  and parsing the inv_idx.txt and doc_mag.txt files \n",
    "# .txt files should be placed in the same directory as this python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_idx = open('inv_idx.txt','r')\n",
    "word = inv_idx.readlines()\n",
    "inv_idx.close()\n",
    "\n",
    "record = []\n",
    "for el in word :\n",
    "    x = el.split('[')\n",
    "    w = x[0][2:-3]\n",
    "    tup = x[1][:-3]\n",
    "    record.append((w,tup))\n",
    "    \n",
    "\n",
    "doc_mag = open('doc_mag.txt','r')\n",
    "doc = doc_mag.readlines()\n",
    "doc_mag.close()\n",
    "\n",
    "record_d = []\n",
    "for el in doc:\n",
    "    x = el.split('(')\n",
    "    did = x[1][:-2]\n",
    "    mag = x[2][4:-3]\n",
    "    record_d.append((did,mag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating table for inverted_ind.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Cosine_values.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2089d77d5e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute('create table if not exists inverted_ind(word varchar(100) PRIMARY KEY, postinglist TEXT)')\n",
    "c.executemany('insert into inverted_ind(word,postinglist) values(?,?)',record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table for doc_mag.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2089d77d5e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute('create table if not exists doc_mag(doc_id Integer PRIMARY KEY, magnitude Integer)')\n",
    "c.executemany('insert into doc_mag(doc_id,magnitude) values(?,?)',record_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for computing cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(query):\n",
    "    try:\n",
    "        s_q = query\n",
    "    #     1. lower_case\n",
    "        query = query.lower()\n",
    "\n",
    "    # 2.filtering noise from data (punctuations + digits + alphanumerics)\n",
    "\n",
    "      # noise = string.punctuation+string.digits\n",
    "        noise = '!\"#$%&\\()*+,-:;<=>?@[\\\\]^_`{|}~'+string.digits\n",
    "        translation = str.maketrans(string.ascii_letters, string.ascii_letters, noise)\n",
    "        query = query.translate(translation)  \n",
    "\n",
    "        trans1 = str.maketrans('\\n\\r\\t\\'/.','      ')\n",
    "        query = query.translate(trans1)\n",
    "\n",
    "    # 3. stop words \n",
    "        query_sw = [word for word in query.split(' ') if word not in stop_words]\n",
    "        query = ''\n",
    "\n",
    "\n",
    "    # 4.stemming/lemmatization\n",
    "\n",
    "        for word in query_sw:\n",
    "            #  temp = ps.stem(word)\n",
    "            temp = lem.lemmatize(word)\n",
    "            #  temp = ps.stem(temp)\n",
    "            query = query+temp+' '\n",
    "\n",
    "    # 5. list of distinct words\n",
    "\n",
    "        query_distinct = list(dict.fromkeys(query.split(' ')))\n",
    "        query_distinct.sort()\n",
    "\n",
    "        try:\n",
    "            query_distinct_2 = [word for word in query_distinct if len(word)>1]\n",
    "            # query_distinct_2.remove('')\n",
    "        except:\n",
    "            print('no strings < length 2')\n",
    "\n",
    "        # count of occurrences of distinct words in doc\n",
    "        count_list = []\n",
    "        list_tf_query = []\n",
    "        for word in query_distinct_2:\n",
    "            count_list.append(query.split(' ').count(word))\n",
    "\n",
    "        max_count_list = max(count_list)\n",
    "\n",
    "        tfidf_val = []\n",
    "        for word in query_distinct_2:\n",
    "            tfidf_val.append(query.split(' ').count(word)/(max_count_list))\n",
    "            list_tf_query.append((word,(query.split(' ').count(word),(query.split(' ').count(word)/(max_count_list)))))\n",
    "\n",
    "\n",
    "        doc_id_list = []\n",
    "        tf_idf_list = []\n",
    "        word_list = []\n",
    "        mag_list = []\n",
    "\n",
    "        cnt = 0\n",
    "\n",
    "        try:\n",
    "\n",
    "            for el in list_tf_query:\n",
    "                word = \"'\"+el[0]+\"'\"\n",
    "\n",
    "                c.execute(\"select * from inverted_ind where word=\"+word)\n",
    "                rslt = c.fetchone()\n",
    "\n",
    "                count = 0\n",
    "\n",
    "                for x in rslt:\n",
    "                    count = count+1\n",
    "                    # tuple\n",
    "                    if count%2==0:\n",
    "                        temp = x.split('(')[1:]\n",
    "\n",
    "                        for x in temp:\n",
    "                            t = x.split(',')\n",
    "                            did = int(t[0])\n",
    "                            tf_idf = float(t[2][1:-1])\n",
    "                            doc_id_list.append(did)\n",
    "                            tf_idf_list.append(tf_idf)\n",
    "                            word_list.append(word_cnt)\n",
    "\n",
    "                    # word\n",
    "                    else:\n",
    "                        word = x\n",
    "                        word_cnt = cnt\n",
    "                        cnt = cnt+1\n",
    "\n",
    "        #                 print(word)\n",
    "\n",
    "        #     print(doc_id_list)\n",
    "        #     print(tf_idf_list)\n",
    "        #     print(word_list)\n",
    "\n",
    "\n",
    "            # sparse matrix of docid x words\n",
    "\n",
    "            matrix = sparse.coo_matrix((tf_idf_list,(doc_id_list,word_list)))\n",
    "            matrix_csr = matrix.tocsr()\n",
    "            matrix_dense = matrix.todense()\n",
    "\n",
    "\n",
    "        #     numerator\n",
    "\n",
    "        #     print(matrix_dense)\n",
    "        #     print(np.array([tfidf_val]).T)\n",
    "        #     print(np.dot(matrix_csr[5],np.array([tfidf_val]).T))\n",
    "\n",
    "            cosine_mat = np.dot(matrix_dense,np.array([tfidf_val]).T)\n",
    "            cosine_list = cosine_mat.tolist()\n",
    "\n",
    "            #numerator\n",
    "            cos_flat_list = [item for sublist in cosine_list for item in sublist]\n",
    "\n",
    "            #denominator\n",
    "            q_mag = 0\n",
    "            for x in list_tf_query:\n",
    "                y=x[1][1]\n",
    "                q_mag = (y*y) + q_mag\n",
    "\n",
    "            doc_id_s = list(dict.fromkeys(doc_id_list))\n",
    "            doc_id_s.sort()\n",
    "\n",
    "\n",
    "            for i in doc_id_s:\n",
    "                c.execute('select magnitude from doc_mag where doc_id='+str(i))\n",
    "                mag_list.append(c.fetchone()[0])\n",
    "\n",
    "            mag_list_1=[]\n",
    "            idx= 0\n",
    "            for val in cos_flat_list:\n",
    "                if val == float(0) :\n",
    "                    mag_list_1.append(0)\n",
    "                else:\n",
    "                    mag_list_1.append(q_mag*mag_list[idx])\n",
    "                    idx = idx + 1\n",
    "\n",
    "\n",
    "        #     print(cos_flat_list)\n",
    "        #     print(mag_list_1)    \n",
    "\n",
    "            cos_list = []\n",
    "            for x in range(len(cos_flat_list)):\n",
    "                if mag_list_1[x]== float(0):\n",
    "                    cos_list.append(0)\n",
    "                else:\n",
    "                    cos_list.append((cos_flat_list[x])/(math.sqrt(mag_list_1[x])))\n",
    "\n",
    "            r_doc = max(cos_list)\n",
    "            r_doc_id = cos_list.index(r_doc)\n",
    "        #     print(cos_list)\n",
    "        #     print(r_doc_id)\n",
    "            file_name= 'input_docs/'+str(r_doc_id)+'.html'\n",
    "            D = open(file_name,'r')\n",
    "\n",
    "            doc_html = D.readlines()\n",
    "            txt = '\\nSearch results for :'+s_q+'\\n\\n'\n",
    "            for x in doc_html:\n",
    "                txt = txt+x\n",
    "            rel_doc = BeautifulSoup(txt).get_text()\n",
    "\n",
    "            print(rel_doc+'\\n')\n",
    "            print('---------------------------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "        except:\n",
    "            print('Your search - '+s_q+' - did not match any documents.')\n",
    "    except:\n",
    "        print('Your search - '+s_q+' - did not match any documents.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e905005e264906b4beadc1cf408288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='search box')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99fcb9d7a906441681489cd12342bce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Search', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e844feb51514729893f368a2147e393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_box = widgets.Text(placeholder= 'search box')\n",
    "search_button = widgets.Button(description='Search')\n",
    "results = widgets.Output()\n",
    "\n",
    "display(text_box,search_button,results)\n",
    "\n",
    "def onclick(event):\n",
    "    with results:\n",
    "        if len(text_box.value)>1:\n",
    "            cosine_sim(text_box.value)\n",
    "        else:\n",
    "            print('No search results for the string')\n",
    "\n",
    "# def cosine_sim(query):\n",
    "#     print('search results for ',query)\n",
    "    \n",
    "search_button.on_click(onclick)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
